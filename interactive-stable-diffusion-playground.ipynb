{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11595956,"sourceType":"datasetVersion","datasetId":7271834}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q --upgrade diffusers transformers accelerate scipy ftfy Pillow opencv-python gradio","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T06:30:26.779588Z","iopub.execute_input":"2025-04-28T06:30:26.779866Z","iopub.status.idle":"2025-04-28T06:32:07.032145Z","shell.execute_reply.started":"2025-04-28T06:30:26.779813Z","shell.execute_reply":"2025-04-28T06:32:07.031236Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.6/322.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\nimport gradio as gr\nimport numpy as np\nimport cv2\nfrom diffusers import (\n    StableDiffusionPipeline,\n    StableDiffusionImg2ImgPipeline,\n    StableDiffusionInpaintPipeline,\n    StableDiffusionControlNetPipeline,\n    ControlNetModel,\n    UniPCMultistepScheduler,\n    DDIMScheduler,\n    EulerAncestralDiscreteScheduler,\n    DPMSolverMultistepScheduler\n)\nimport gc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T06:33:06.367939Z","iopub.execute_input":"2025-04-28T06:33:06.368655Z","iopub.status.idle":"2025-04-28T06:33:32.301700Z","shell.execute_reply.started":"2025-04-28T06:33:06.368628Z","shell.execute_reply":"2025-04-28T06:33:32.300750Z"}},"outputs":[{"name":"stderr","text":"2025-04-28 06:33:20.517626: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745822000.712988      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745822000.771858      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n\nprint(f\"Using device: {device}\")\nprint(f\"Using dtype: {torch_dtype}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T06:33:32.303157Z","iopub.execute_input":"2025-04-28T06:33:32.303961Z","iopub.status.idle":"2025-04-28T06:33:32.311016Z","shell.execute_reply.started":"2025-04-28T06:33:32.303928Z","shell.execute_reply":"2025-04-28T06:33:32.309645Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nUsing dtype: torch.float16\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def load_t2i_pipe(model_id=\"runwayml/stable-diffusion-v1-5\"):\n    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch_dtype)\n    pipe = pipe.to(device)\n    return pipe\n\ndef load_i2i_pipe(model_id=\"runwayml/stable-diffusion-v1-5\"):\n    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, torch_dtype=torch_dtype)\n    pipe = pipe.to(device)\n    return pipe\n\ndef load_inpaint_pipe(model_id=\"runwayml/stable-diffusion-v1-5\"):\n    inpaint_model_id = \"runwayml/stable-diffusion-inpainting\"\n    try:\n        pipe = StableDiffusionInpaintPipeline.from_pretrained(inpaint_model_id, torch_dtype=torch_dtype)\n    except Exception as e:\n        print(f\"Inpainting model yüklenemedi ({e}), standart model kullanılıyor.\")\n        pipe = StableDiffusionInpaintPipeline.from_pretrained(model_id, torch_dtype=torch_dtype)\n    pipe = pipe.to(device)\n    return pipe\n\ndef load_controlnet_pipe(model_id=\"runwayml/stable-diffusion-v1-5\", controlnet_model_id=\"lllyasviel/sd-controlnet-canny\"):\n    controlnet = ControlNetModel.from_pretrained(controlnet_model_id, torch_dtype=torch_dtype)\n    pipe = StableDiffusionControlNetPipeline.from_pretrained(\n        model_id, controlnet=controlnet, torch_dtype=torch_dtype\n    )\n    pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n    pipe = pipe.to(device)\n    return pipe\n\nprint(\"Loading pipelines...\")\ntry:\n    pipe_t2i = load_t2i_pipe()\n    pipe_i2i = load_i2i_pipe()\n    pipe_inpaint = load_inpaint_pipe()\n    pipe_controlnet_canny = load_controlnet_pipe()\n    print(\"All pipelines loaded successfully.\")\n    PIPELINES_LOADED = True\nexcept Exception as e:\n    print(f\"Error loading all pipelines upfront: {e}\")\n    print(\"Pipelines will be loaded on demand (slower).\")\n    PIPELINES_LOADED = False\n    pipe_t2i, pipe_i2i, pipe_inpaint, pipe_controlnet_canny = None, None, None, None\n\ndef cleanup_memory():\n    \"\"\"Belleği temizlemeye çalışır.\"\"\"\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    print(\"Memory cleanup attempted.\")\n\nschedulers = {\n    \"Default (PNDM)\": None, \n    \"DDIM\": DDIMScheduler,\n    \"Euler Ancestral\": EulerAncestralDiscreteScheduler,\n    \"DPM++ 2M Karras\": DPMSolverMultistepScheduler \n}\n\ndef set_scheduler(pipe, scheduler_name):\n    scheduler_class = schedulers.get(scheduler_name)\n    if pipe is not None and scheduler_class is not None:\n        print(f\"Setting scheduler to {scheduler_name}\")\n        pipe.scheduler = scheduler_class.from_config(pipe.scheduler.config)\n    elif pipe is not None:\n        print(f\"Setting scheduler to Default\")\n        pass \n    return pipe","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T06:33:35.499196Z","iopub.execute_input":"2025-04-28T06:33:35.499699Z","iopub.status.idle":"2025-04-28T06:34:17.525817Z","shell.execute_reply.started":"2025-04-28T06:33:35.499676Z","shell.execute_reply":"2025-04-28T06:34:17.525203Z"}},"outputs":[{"name":"stdout","text":"Loading pipelines...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f5536349e2b4e378e6ee1f6d81d4f21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21e98fa75b444f18839ff69ee59339cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f05489d48d5043b4bbcdc774b6de6480"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler_config.json:   0%|          | 0.00/308 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3532cf553ad14cbdb373294379dca916"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32372ab675a74bf0944abdc4c7d0ca52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"435f45426a7f40f8b59a60cd8f6a4431"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54c040931cda497085555cf5ae81011a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"611f911c19bc4d579d2d5afa7369f5c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d120960327447ccaa3e0ecd59ef10aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac47966e8da84ec597c87bd246e43fc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff0eee8a57584abd846427f4c3b89496"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b46ed5cc12154340ad93917f33ae2401"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73d5ad838d104a9c9770117d33182be0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74193b6e46164f6582db4d4d4ae86530"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17f5a635e0d74ca581947c509839f998"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3fbd9d969134600b92e154892eaa70c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0f452fc9d7d4e18a743aeaf649e2b0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ab6d9c94fd646a5af31d7fcde486bab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/548 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7b2edb74f734b73b525954b63a13dfc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b793b49ab58448128ffafe37134442cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/748 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6565a6fcc39e49a9be6d087caf3eb31d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f24e165b08f4e1680ca911fc3e3b113"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f6ac6ddb1e24840ab95a9cf2eb4fda2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler_config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e40e92d6d4864bb4a0eecc89dfcd9476"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f618b8966d54f119bb2d82d9a913bdb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9dcf46376a041f8aaef186246859abf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.78k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"754db3c441b74eb49ba204185e797dfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bea84e4d3f345fd94b70761e4b0becd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/552 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"addfd3f4a464411483383280a9d8b33a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1726d5f8332c449aaad1dfaf035d03ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51bb5a44bbde4b36819f7efadd811cd3"}},"metadata":{}},{"name":"stdout","text":"Inpainting model yüklenemedi (Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-inpainting/snapshots/8a4288a76071f7280aedbdb3253bdb9e9d5d84bb/safety_checker.), standart model kullanılıyor.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f0b2a519bf64a18b40224bdbbdfeb2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/920 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1a7be806734411b8b6c83eaa179ca21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/1.45G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3a7bd26d01a4483a8aa1b8158fc7dfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b595002734d04422a35f2818ef744589"}},"metadata":{}},{"name":"stdout","text":"All pipelines loaded successfully.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def generate_i2i(init_image_pil, prompt, negative_prompt, strength, num_steps, guidance_scale, scheduler_name):\n    global pipe_i2i\n    if init_image_pil is None:\n        return None, \"Please upload an initial image.\"\n\n    if not PIPELINES_LOADED or pipe_i2i is None:\n        print(\"Loading I2I pipeline on demand...\")\n        pipe_i2i = load_i2i_pipe()\n        cleanup_memory()\n    if pipe_i2i is None: return None, \"I2I Pipeline yüklenemedi.\"\n\n    pipe_i2i = set_scheduler(pipe_i2i, scheduler_name)\n\n    target_size = (512, 512)\n    init_image_pil = init_image_pil.resize(target_size)\n\n    try:\n        print(f\"Generating I2I image for prompt: {prompt}\")\n        with torch.autocast(\"cuda\" if device == \"cuda\" else \"cpu\"):\n            image = pipe_i2i(\n                prompt=prompt,\n                negative_prompt=negative_prompt,\n                image=init_image_pil,\n                strength=strength,\n                num_inference_steps=int(num_steps),\n                guidance_scale=guidance_scale\n            ).images[0]\n        print(\"I2I image generated.\")\n        return image, \"Success\"\n    except Exception as e:\n        print(f\"I2I Error: {e}\")\n        cleanup_memory()\n        return None, f\"Error: {e}\"\n\ndef generate_controlnet_canny(control_image_pil, prompt, negative_prompt, num_steps, guidance_scale, canny_low, canny_high):\n    global pipe_controlnet_canny\n    if control_image_pil is None:\n        return None, None, \"Please upload an image to extract edges.\"\n\n    if not PIPELINES_LOADED or pipe_controlnet_canny is None:\n        print(\"Loading ControlNet Canny pipeline on demand...\")\n        pipe_controlnet_canny = load_controlnet_pipe()\n        cleanup_memory()\n\n    if pipe_controlnet_canny is None: return None, None, \"ControlNet Canny Pipeline yüklenemedi.\"\n\n    control_image_np = np.array(control_image_pil)\n\n    h, w, _ = control_image_np.shape\n    if max(h, w) > 600:\n         scale = 600 / max(h, w)\n         new_w, new_h = int(w*scale), int(h*scale)\n         control_image_np = cv2.resize(control_image_np, (new_w, new_h))\n         control_image_pil = Image.fromarray(control_image_np) # PIL'i de güncelle\n\n    canny_map_np = cv2.Canny(control_image_np, canny_low, canny_high)\n    canny_map_pil = Image.fromarray(cv2.cvtColor(canny_map_np, cv2.COLOR_GRAY2BGR))\n\n    try:\n        print(f\"Generating ControlNet Canny image for prompt: {prompt}\")\n        with torch.autocast(\"cuda\" if device == \"cuda\" else \"cpu\"):\n             image = pipe_controlnet_canny(\n                 prompt=prompt,\n                 negative_prompt=negative_prompt,\n                 image=canny_map_pil,\n                 num_inference_steps=int(num_steps),\n                 guidance_scale=guidance_scale\n             ).images[0]\n        print(\"ControlNet Canny image generated.\")\n        return canny_map_pil, image, \"Success\"\n    except Exception as e:\n        print(f\"ControlNet Canny Error: {e}\")\n        cleanup_memory()\n        return None, None, f\"Error: {e}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T06:34:30.995648Z","iopub.execute_input":"2025-04-28T06:34:30.996018Z","iopub.status.idle":"2025-04-28T06:34:31.007108Z","shell.execute_reply.started":"2025-04-28T06:34:30.995994Z","shell.execute_reply":"2025-04-28T06:34:31.006311Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def generate_t2i(prompt, negative_prompt, num_steps, guidance_scale, scheduler_name):\n    global pipe_t2i\n    if not PIPELINES_LOADED or pipe_t2i is None:\n        print(\"Loading T2I pipeline on demand...\")\n        pipe_t2i = load_t2i_pipe()\n        cleanup_memory()\n\n    if pipe_t2i is None: return None, \"T2I Pipeline yüklenemedi.\"\n\n    pipe_t2i = set_scheduler(pipe_t2i, scheduler_name)\n\n    try:\n        print(f\"Generating T2I image for prompt: {prompt}\")\n        with torch.autocast(\"cuda\" if device == \"cuda\" else \"cpu\"):\n             image = pipe_t2i(\n                prompt=prompt,\n                negative_prompt=negative_prompt,\n                num_inference_steps=int(num_steps),\n                guidance_scale=guidance_scale\n             ).images[0]\n        print(\"T2I image generated.\")\n        return image, \"Success\"\n    except Exception as e:\n        print(f\"T2I Error: {e}\")\n        cleanup_memory()\n        return None, f\"Error: {e}\"\ndef generate_inpaint(image_dict, prompt, negative_prompt, num_steps, guidance_scale, scheduler_name):\n    global pipe_inpaint\n    if image_dict is None or \"image\" not in image_dict or \"mask\" not in image_dict:\n         return None, \"Please provide an image and draw a mask.\"\n\n    init_image_pil = image_dict[\"image\"]\n    mask_image_pil = image_dict[\"mask\"]\n\n    if not PIPELINES_LOADED or pipe_inpaint is None:\n        print(\"Loading Inpaint pipeline on demand...\")\n        pipe_inpaint = load_inpaint_pipe()\n        cleanup_memory()\n\n    if pipe_inpaint is None: return None, \"Inpaint Pipeline yüklenemedi.\"\n\n    pipe_inpaint = set_scheduler(pipe_inpaint, scheduler_name)\n\n    target_size = (512, 512)\n    init_image_pil = init_image_pil.resize(target_size)\n    mask_image_pil = mask_image_pil.resize(target_size).convert(\"L\")\n\n\n    try:\n        print(f\"Generating Inpaint image for prompt: {prompt}\")\n        with torch.autocast(\"cuda\" if device == \"cuda\" else \"cpu\"):\n            image = pipe_inpaint(\n                prompt=prompt,\n                negative_prompt=negative_prompt,\n                image=init_image_pil,\n                mask_image=mask_image_pil,\n                num_inference_steps=int(num_steps),\n                guidance_scale=guidance_scale\n            ).images[0]\n        print(\"Inpaint image generated.\")\n        return image, \"Success\"\n    except Exception as e:\n        print(f\"Inpaint Error: {e}\")\n        cleanup_memory()\n        return None, f\"Error: {e}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T06:34:33.466419Z","iopub.execute_input":"2025-04-28T06:34:33.466981Z","iopub.status.idle":"2025-04-28T06:34:33.474857Z","shell.execute_reply.started":"2025-04-28T06:34:33.466961Z","shell.execute_reply":"2025-04-28T06:34:33.474233Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"loaded_lora = None\n\ndef load_lora_weights(lora_id_or_path):\n    global pipe_t2i, loaded_lora\n    if not pipe_t2i:\n        return \"T2I pipeline not loaded yet. Generate an image first.\"\n\n    unload_lora_weights()\n\n    if not lora_id_or_path:\n        return \"Please provide a LoRA ID (Hugging Face Hub) or local path.\"\n\n    try:\n        print(f\"Loading LoRA: {lora_id_or_path}\")\n        if \"/\" in lora_id_or_path and not lora_id_or_path.startswith(\"/\"):\n             pipe_t2i.load_lora_weights(lora_id_or_path) \n        else:\n             weight_name = \"pytorch_lora_weights.safetensors\"\n             if lora_id_or_path.endswith(\".bin\"): weight_name=\"pytorch_lora_weights.bin\"\n             pipe_t2i.load_lora_weights(lora_id_or_path, weight_name=weight_name)\n\n        loaded_lora = lora_id_or_path\n        print(f\"LoRA '{lora_id_or_path}' loaded successfully.\")\n        return f\"LoRA '{lora_id_or_path}' loaded. Remember to use trigger words in prompt if needed.\"\n    except Exception as e:\n        print(f\"Error loading LoRA: {e}\")\n        return f\"Error loading LoRA: {e}\"\n\ndef unload_lora_weights():\n    global pipe_t2i, loaded_lora\n    if pipe_t2i and loaded_lora:\n        try:\n            print(f\"Unloading LoRA: {loaded_lora}\")\n            pipe_t2i.unload_lora_weights()\n            print(\"LoRA unloaded.\")\n            status = f\"LoRA '{loaded_lora}' unloaded.\"\n            loaded_lora = None\n            cleanup_memory()\n            return status\n        except Exception as e:\n             print(f\"Error unloading LoRA: {e}\")\n             return f\"Error unloading LoRA: {e}\"\n    elif pipe_t2i:\n        return \"No LoRA currently loaded.\"\n    else:\n        return \"T2I pipeline not loaded.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T06:34:36.015559Z","iopub.execute_input":"2025-04-28T06:34:36.016227Z","iopub.status.idle":"2025-04-28T06:34:36.022509Z","shell.execute_reply.started":"2025-04-28T06:34:36.016203Z","shell.execute_reply":"2025-04-28T06:34:36.021768Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"with gr.Blocks() as demo:\n    gr.Markdown(\"# Interactive Stable Diffusion Playground\")\n    gr.Markdown(\"Kaggle üzerinde çalışan Diffusers tabanlı bir arayüz.\")\n\n    with gr.Tab(\"Text-to-Image\"):\n        with gr.Row():\n            with gr.Column(scale=2):\n                t2i_prompt = gr.Textbox(label=\"Prompt (Ne çizmek istersiniz?)\")\n                t2i_neg_prompt = gr.Textbox(label=\"Negative Prompt (Neleri istemezsiniz?)\", value=\"low quality, blurry, deformed\")\n                t2i_scheduler = gr.Dropdown(list(schedulers.keys()), label=\"Scheduler\", value=\"Default (PNDM)\")\n                with gr.Row():\n                    t2i_steps = gr.Slider(minimum=10, maximum=100, step=1, value=30, label=\"Inference Steps\")\n                    t2i_guidance = gr.Slider(minimum=1, maximum=20, step=0.5, value=7.5, label=\"Guidance Scale\")\n                t2i_button = gr.Button(\"Generate Image\", variant=\"primary\")\n            with gr.Column(scale=1):\n                t2i_output = gr.Image(label=\"Generated Image\")\n                t2i_status = gr.Textbox(label=\"Status\", interactive=False)\n\n        t2i_button.click(\n            generate_t2i,\n            inputs=[t2i_prompt, t2i_neg_prompt, t2i_steps, t2i_guidance, t2i_scheduler],\n            outputs=[t2i_output, t2i_status]\n        )\n    with gr.Tab(\"Image-to-Image\"):\n        with gr.Row():\n            with gr.Column(scale=1):\n                i2i_input_image = gr.Image(type=\"pil\", label=\"Initial Image\")\n            with gr.Column(scale=1):\n                i2i_output_image = gr.Image(label=\"Generated Image\")\n                i2i_status = gr.Textbox(label=\"Status\", interactive=False)\n\n        i2i_prompt = gr.Textbox(label=\"Prompt (Ne olmasını istersiniz?)\")\n        i2i_neg_prompt = gr.Textbox(label=\"Negative Prompt\", value=\"low quality, blurry, deformed\")\n        i2i_scheduler = gr.Dropdown(list(schedulers.keys()), label=\"Scheduler\", value=\"Default (PNDM)\")\n        with gr.Row():\n            i2i_strength = gr.Slider(minimum=0.0, maximum=1.0, step=0.05, value=0.75, label=\"Strength (Değişim Miktarı)\")\n            i2i_steps = gr.Slider(minimum=10, maximum=100, step=1, value=30, label=\"Inference Steps\")\n            i2i_guidance = gr.Slider(minimum=1, maximum=20, step=0.5, value=7.5, label=\"Guidance Scale\")\n        i2i_button = gr.Button(\"Generate Image\", variant=\"primary\")\n\n        i2i_button.click(\n            generate_i2i,\n            inputs=[i2i_input_image, i2i_prompt, i2i_neg_prompt, i2i_strength, i2i_steps, i2i_guidance, i2i_scheduler],\n            outputs=[i2i_output_image, i2i_status]\n        )\n    with gr.Tab(\"Inpainting\"):\n        gr.Markdown(\"Upload an image and draw a mask over the area you want to change.\")\n        with gr.Row():\n            inpaint_input_image = gr.Image(type=\"pil\", label=\"Image & Mask\", height=400)\n            with gr.Column():\n                inpaint_output_image = gr.Image(label=\"Generated Image\", height=400)\n                inpaint_status = gr.Textbox(label=\"Status\", interactive=False)\n\n        inpaint_prompt = gr.Textbox(label=\"Prompt (Maskelenen alana ne çizilsin?)\")\n        inpaint_neg_prompt = gr.Textbox(label=\"Negative Prompt\", value=\"low quality, blurry, deformed\")\n        inpaint_scheduler = gr.Dropdown(list(schedulers.keys()), label=\"Scheduler\", value=\"Default (PNDM)\")\n        with gr.Row():\n            inpaint_steps = gr.Slider(minimum=10, maximum=100, step=1, value=50, label=\"Inference Steps\")\n            inpaint_guidance = gr.Slider(minimum=1, maximum=20, step=0.5, value=8.0, label=\"Guidance Scale\")\n        inpaint_button = gr.Button(\"Generate Inpainted Image\", variant=\"primary\")\n\n        inpaint_button.click(\n            generate_inpaint,\n            inputs=[inpaint_input_image, inpaint_prompt, inpaint_neg_prompt, inpaint_steps, inpaint_guidance, inpaint_scheduler],\n            outputs=[inpaint_output_image, inpaint_status]\n        )\n    with gr.Tab(\"ControlNet (Canny Edge)\"):\n        gr.Markdown(\"Upload an image. Its edges will be detected (Canny) and used to guide the generation process based on your prompt.\")\n        with gr.Row():\n            with gr.Column(scale=1):\n                cn_input_image = gr.Image(type=\"pil\", label=\"Input Image for Edge Detection\")\n                with gr.Row():\n                   canny_low_thr = gr.Slider(minimum=1, maximum=255, step=1, value=100, label=\"Canny Low Threshold\")\n                   canny_high_thr = gr.Slider(minimum=1, maximum=255, step=1, value=200, label=\"Canny High Threshold\")\n            with gr.Column(scale=1):\n                 cn_canny_map = gr.Image(label=\"Detected Canny Edges\")\n            with gr.Column(scale=1):\n                cn_output_image = gr.Image(label=\"Generated Image Guided by Edges\")\n                cn_status = gr.Textbox(label=\"Status\", interactive=False)\n\n        cn_prompt = gr.Textbox(label=\"Prompt (Kenarlara uygun ne çizilsin?)\")\n        cn_neg_prompt = gr.Textbox(label=\"Negative Prompt\", value=\"low quality, blurry, deformed, text, watermark\")\n        with gr.Row():\n            cn_steps = gr.Slider(minimum=10, maximum=100, step=1, value=25, label=\"Inference Steps\")\n            cn_guidance = gr.Slider(minimum=1, maximum=20, step=0.5, value=7.5, label=\"Guidance Scale\")\n        cn_button = gr.Button(\"Generate with ControlNet\", variant=\"primary\")\n\n        cn_button.click(\n            generate_controlnet_canny,\n            inputs=[cn_input_image, cn_prompt, cn_neg_prompt, cn_steps, cn_guidance, canny_low_thr, canny_high_thr],\n            outputs=[cn_canny_map, cn_output_image, cn_status]\n        )\n    with gr.Tab(\"LoRA Loader (T2I Only)\"):\n        gr.Markdown(\"Load custom styles or concepts using LoRA weights. Enter Hugging Face Hub ID (e.g., `ostris/ikea-instructions-lora-sdv1-5`) or a local path in Kaggle (e.g., `/kaggle/input/my-lora/lora.safetensors`). Affects Text-to-Image tab only for now.\")\n        with gr.Row():\n             lora_input = gr.Textbox(label=\"LoRA Hub ID or Local Path\")\n             lora_load_btn = gr.Button(\"Load LoRA\")\n             lora_unload_btn = gr.Button(\"Unload LoRA\")\n        lora_status = gr.Textbox(label=\"LoRA Status\", interactive=False)\n\n        lora_load_btn.click(load_lora_weights, inputs=[lora_input], outputs=[lora_status])\n        lora_unload_btn.click(unload_lora_weights, inputs=[], outputs=[lora_status])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T06:34:38.372728Z","iopub.execute_input":"2025-04-28T06:34:38.373044Z","iopub.status.idle":"2025-04-28T06:34:39.027002Z","shell.execute_reply.started":"2025-04-28T06:34:38.373006Z","shell.execute_reply":"2025-04-28T06:34:39.026212Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"demo.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T06:34:44.774124Z","iopub.execute_input":"2025-04-28T06:34:44.774613Z","iopub.status.idle":"2025-04-28T06:34:44.778045Z","shell.execute_reply.started":"2025-04-28T06:34:44.774591Z","shell.execute_reply":"2025-04-28T06:34:44.777304Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"demo.launch(debug=True, share=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T06:34:45.631955Z","iopub.execute_input":"2025-04-28T06:34:45.632507Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://7d3f23f8814a339fd3.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://7d3f23f8814a339fd3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"name":"stdout","text":"Loading LoRA: /kaggle/input/lora-tensors/pytorch_lora_weights.safetensors\n","output_type":"stream"},{"name":"stderr","text":"No LoRA keys associated to CLIPTextModel found with the prefix='text_encoder'. This is safe to ignore if LoRA state dict didn't originally have any CLIPTextModel related params. You can also try specifying `prefix=None` to resolve the warning. Otherwise, open an issue if you think it's unexpected: https://github.com/huggingface/diffusers/issues/new\n","output_type":"stream"},{"name":"stdout","text":"LoRA '/kaggle/input/lora-tensors/pytorch_lora_weights.safetensors' loaded successfully.\nSetting scheduler to Default\nGenerating T2I image for prompt: familyguy style, a lawyer arguing in court\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab07916c63564d3b998687111034acd8"}},"metadata":{}},{"name":"stdout","text":"T2I image generated.\nSetting scheduler to Default\nGenerating T2I image for prompt: batman in sky\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"172f8b47395d49dc8556d1c6f092ba70"}},"metadata":{}},{"name":"stdout","text":"T2I image generated.\nUnloading LoRA: /kaggle/input/lora-tensors/pytorch_lora_weights.safetensors\nLoRA unloaded.\nMemory cleanup attempted.\nSetting scheduler to Default\nGenerating T2I image for prompt: batman in sky\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90cdd76c9d1b4935b6b26216e0e5a2ea"}},"metadata":{}},{"name":"stdout","text":"T2I image generated.\nSetting scheduler to DDIM\nGenerating T2I image for prompt: batman in sky\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/46 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c4b65f9f7fc48988c6f40c2c32e13f1"}},"metadata":{}},{"name":"stdout","text":"T2I image generated.\nSetting scheduler to DDIM\nGenerating T2I image for prompt: duck in sky\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/46 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2547f48c55d94a249c549040a235d4f2"}},"metadata":{}},{"name":"stdout","text":"T2I image generated.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}